{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bf900af",
   "metadata": {},
   "source": [
    "#### 1) Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed1d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re \n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer  # lemmatize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import , TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer #Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Tfid\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost \n",
    "from sklearn.metrics  import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7475388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a85b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e030b86",
   "metadata": {},
   "source": [
    "# 3)TRAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a1c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model\n",
    "\n",
    "# “stratified”: generates predictions by respecting the training set’s class distribution.\n",
    "\n",
    "dc = DummyClassifier(strategy=\"stratified\")\n",
    "dc.fit(Xtr, Ytr)\n",
    "pred = dc.predict(Xde)\n",
    "print(classification_report(Yde, pred, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c88589",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(Xtr, Ytr)\n",
    "pred = dt.predict(Xde)\n",
    "print(classification_report(Yde, pred, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=40)\n",
    "rf.fit(Xtr, Ytr)\n",
    "pred = rf.predict(Xde)\n",
    "print(classification_report(Yde, pred, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6ba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multinomial Naive Bayesian\n",
    "nb = MultinomialNB()\n",
    "nb.fit(Xtr, Ytr)\n",
    "pred = nb.predict(Xde)\n",
    "print(classification_report(Yde, pred, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f0b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Support Vector Classification\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(Xtr, Ytr)\n",
    "pred = svc.predict(Xde)\n",
    "print(classification_report(Yde, pred, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multilayered Perceptron\n",
    "mlp = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100, 20), random_state=1, max_iter=400)\n",
    "mlp.fit(Xtr, Ytr)\n",
    "pred = mlp.predict(Xde)\n",
    "print(classification_report(Yde, pred, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd7485",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Final Model: Multinomial Naive Bayesian\n",
    "# Multinomial Naive Bayesian works the best. Lets run NB on our test data and get the confusion matrix and its heat map.\n",
    "\n",
    "Predict test data\n",
    "pred = nb.predict(Xte)\n",
    "print(classification_report(Yte, pred, target_names=encoder.classes_))\n",
    "sns.heatmap(confusion_matrix(Yte, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c51481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multinomial Naive Bayesian Explained\n",
    "We will now try to understand why Naive Bayesian is getting good results. We will get all the coefficents of the features and then print the top 20 words based on its weight. As we can see all the words are closely related to the category, hence multinomial naive bayesian predcits correct label with good F1 score.\n",
    "\n",
    "nb1 = MultinomialNB()\n",
    "nb1.fit(Xtr_whole, Ytr_whole)\n",
    "coefs = nb1.coef_\n",
    "target_names = encoder.classes_\n",
    "\n",
    "for i in range(len(target_names)):\n",
    "    words = []\n",
    "    for j in coefs[i].argsort()[-20:]:\n",
    "        words.append(reverse_vocabulary[j])\n",
    "    print (target_names[i], '-', words, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e99de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551bce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d120be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load word and char tfidf vectors\n",
    "PATH_ROOT = r'../' \n",
    "\n",
    "#  load dataset\n",
    "def load_data(path):\n",
    "    with open(PATH_ROOT + path, 'rb') as handle:\n",
    "        dataset = pickle.load(handle)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe70675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Word&Char TF-IDF Vectors\n",
    "\n",
    "with open(PATH_ROOT + 'vectors/interpress_news_category_tr_lite_train_cleaned_tfidf_word_2000.pkl', 'rb') as handle:\n",
    "    word_tfidf = pickle.load(handle)\n",
    "\n",
    "with open(PATH_ROOT + 'vectors/interpress_news_category_tr_lite_train_cleaned_tfidf_char_2000.pkl', 'rb') as handle:\n",
    "    char_tfidf = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b3fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Cleaned Train&Test Dataset\n",
    "\n",
    "df_train = load_data(r\"datasets/interpress_news_category_tr_lite_train_cleaned.pkl\")\n",
    "df_test = load_data(r\"datasets/interpress_news_category_tr_lite_test_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ea5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Transform Word&Char\n",
    "\n",
    "train_tf_word_transformed = word_tfidf.transform(df_train['clean_content'])\n",
    "train_tf_char_transformed = char_tfidf.transform(df_train['clean_content'])\n",
    "\n",
    "test_tf_word_transformed = word_tfidf.transform(df_test['clean_content'])\n",
    "test_tf_char_transformed = char_tfidf.transform(df_test['clean_content'])\n",
    "\n",
    "tf_train_features = hstack([train_tf_word_transformed, train_tf_char_transformed])\n",
    "tf_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe4c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN - SVM\n",
    "\n",
    "#  train SVM model\n",
    "clf = svm.SVC(kernel='linear', gamma='auto')\n",
    "clf.fit(tf_train_features, df_train['category'])\n",
    "\n",
    "#  save model\n",
    "filename = PATH_ROOT + 'models/interpress_news_category_tr_lite_classifier_svm_model_4000.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f088a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score ACC - TEST\n",
    "\n",
    "#  stack word and char tfidf features for train\n",
    "tf_test_featured = hstack([test_tf_word_transformed, test_tf_char_transformed])\n",
    "\n",
    "#  get accuracy\n",
    "clf.score(tf_test_featured, df_test['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c8d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "\n",
    "\n",
    "#  get predictions and actual labels\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for i, news in enumerate(tqdm(df_test['clean_content'])):\n",
    "    word_transformed_news = word_tfidf.transform([news])\n",
    "    char_transformed_news = char_tfidf.transform([news])\n",
    "    news_featured = hstack([word_transformed_news, char_transformed_news])\n",
    "    result = clf.predict(news_featured)[0]\n",
    "    y_pred.append(result)\n",
    "    y_true.append(df_test['category'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d198eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification Report\n",
    "#  show classification report\n",
    "labels = [\"Kültür-Sanat\",\"Ekonomi\",\"Siyaset\",\"Eğitim\",\"Dünya\",\"Spor\",\"Teknoloji\",\"Magazin\",\"Sağlık\",\"Gündem\"]\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  visualize confusion matrix\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0b79f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e025150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fba55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier(early_stopping=True,penalty='l2',alpha=0.00001)\n",
    "sgd_model.fit(X_train,y_train)\n",
    "pred_sgd = sgd_model.predict(X_val)\n",
    "print(\"first 20 actual labels\")\n",
    "print(y_val.tolist()[:20])\n",
    "print(\"first 20 predicted labels\")\n",
    "print(pred_sgd.tolist()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0271f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Confusion matrix\n",
    "def confusion_mat(color):\n",
    "    cof=confusion_matrix(y_val, pred_sgd)\n",
    "    cof=pd.DataFrame(cof, index=[i for i in range(1,5)], columns=[i for i in range(1,5)])\n",
    "    sns.set(font_scale=1.5)\n",
    "    plt.figure(figsize=(8,8));\n",
    "\n",
    "    sns.heatmap(cof, cmap=color,linewidths=1, annot=True,square=True, fmt='d', cbar=False,xticklabels=['World','Sports','Business','Science'],yticklabels=['World','Sports','Business','Science']);\n",
    "    plt.xlabel(\"Predicted Classes\");\n",
    "    plt.ylabel(\"Actual Classes\");\n",
    "confusion_mat('Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e48a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision ,Recall,F1-Score\n",
    "print('\\nClassification Report\\n')\n",
    "print((classification_report(y_val,pred_sgd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c435a916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec587c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy\n",
    "b1 = round(accuracy_score(y_val,pred_sgd)*100,4)\n",
    "b2 = round(100-accuracy_score(y_val,pred_sgd)*100,4)\n",
    "print('Accuracy:',b1)\n",
    "print('Error:',b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56bdddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e9c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98afcc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier(criterion='gini')\n",
    "dt_model.fit(X_train,y_train)\n",
    "pred_dtg = dt_model.predict(X_val)\n",
    "print(\"first 20 actual labels\")\n",
    "print(y_val.tolist()[:20])\n",
    "print(\"first 20 predicted labels\")\n",
    "print(pred_dtg.tolist()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ab4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Confusion matrix\n",
    "def confusion_mat(color):\n",
    "    cof=confusion_matrix(y_val, pred_dtg)\n",
    "    cof=pd.DataFrame(cof, index=[i for i in range(1,5)], columns=[i for i in range(1,5)])\n",
    "    sns.set(font_scale=1.5)\n",
    "    plt.figure(figsize=(8,8));\n",
    "\n",
    "    sns.heatmap(cof, cmap=color,linewidths=1, annot=True,square=True, fmt='d', cbar=False,xticklabels=['World','Sports','Business','Science'],yticklabels=['World','Sports','Business','Science']);\n",
    "    plt.xlabel(\"Predicted Classes\");\n",
    "    plt.ylabel(\"Actual Classes\");\n",
    "confusion_mat('RdYlBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1326989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision, Recall ,F1-Score\n",
    "print('\\nClassification Report\\n')\n",
    "print((classification_report(y_val,pred_dtg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy\n",
    "c1 = round(accuracy_score(y_val,pred_dtg)*100,4)\n",
    "c2 = round(100-accuracy_score(y_val,pred_dtg)*100,4)\n",
    "print('Accuracy:',c1)\n",
    "print('Error:',c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92aaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparison of Accuracies of Different Models for Dtrain and Dvalidation\n",
    "sns.set()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "Models = [\"Logistic_Regression\",\"Stocastic_Gradient_Descent\",\"Decison_Tree\"]\n",
    "Accuracy=[a1,b1,c1]\n",
    "ax.bar(Models,Accuracy,color=['#702963','#8a2be2','#9966cc']);\n",
    "for i in ax.patches:\n",
    "    ax.text(i.get_x()+.1, i.get_height()-7.8, str(round(i.get_height(),2))+'%', fontsize=20, color='white')\n",
    "plt.title('Comparison of Different Classification Models');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.xlabel('Classification Models');\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f87fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b77545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Checking accuracy for Unseen data (Dtest) in Logistic Regression\n",
    "pred_lr_for_unseen = lr_model.predict(X_test)\n",
    "a11 = round(accuracy_score(y_test,pred_lr_for_unseen)*100,4)\n",
    "a22 = round(100-accuracy_score(y_test,pred_lr_for_unseen)*100,4)\n",
    "print('Accuracy:',a11)\n",
    "print('Error:',a22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ef95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db86cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Checking accuracy for Unseen data (Dtest) in SGD\n",
    "pred_sgd_for_unseen = sgd_model.predict(X_test)\n",
    "b11 = round(accuracy_score(y_test,pred_sgd_for_unseen)*100,4)\n",
    "b22 = round(100-accuracy_score(y_test,pred_sgd_for_unseen)*100,4)\n",
    "print('Accuracy:',b11)\n",
    "print('Error:',b22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d5af83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Checking accuracy for Unseen data (Dtest) in Decision Tree\n",
    "pred_dtg_for_unseen = dt_model.predict(X_test)\n",
    "c11 = round(accuracy_score(y_test,pred_dtg_for_unseen)*100,4)\n",
    "c22 = round(100-accuracy_score(y_test,pred_dtg_for_unseen)*100,4)\n",
    "print('Accuracy:',c11)\n",
    "print('Error:',c22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc36667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874c7af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparison of Accuracies of Different Models on Unseen data (Dtest)\n",
    "sns.set()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "Models = [\"Logistic_Regression\",\"Stocastic_Gradient_Descent\",\"Decison_Tree\"]\n",
    "Accuracy=[a11,b11,c11]\n",
    "ax.bar(Models,Accuracy,color=['#702963','#8a2be2','#9966cc']);\n",
    "for i in ax.patches:\n",
    "    ax.text(i.get_x()+.1, i.get_height()-7.8, str(round(i.get_height(),2))+'%', fontsize=20, color='white')\n",
    "plt.title('Comparison of Different Classification Models');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.xlabel('Classification Models');\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c32836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import TfIdfVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "#Replace NaN with an empty string\n",
    "metadata['overview'] = metadata['overview'].fillna('')\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(metadata['overview'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array mapping from feature integer indices to feature name.\n",
    "tfidf.get_feature_names()[5000:5010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c27e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ac4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1de7ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943eb357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a reverse map of indices and movie titles\n",
    "indices = pd.Series(metadata.index, index=metadata['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c303bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in movie title as input and outputs most similar movies\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return metadata['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a6b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations('The Dark Knight Rises')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360de48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations('The Godfather')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer and create the count matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(metadata['soup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e8798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8097191",
   "metadata": {},
   "source": [
    "One key difference is that you use the CountVectorizer() instead of TF-IDF. This is because you do not want to down-weight the actor/director's presence if he or she has acted or directed in relatively more movies. It doesn't make much intuitive sense to down-weight them in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f44062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Cosine Similarity matrix based on the count_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim2 = cosine_similarity(count_matrix, count_matrix)\n",
    "# Reset index of your main DataFrame and construct reverse mapping as before\n",
    "metadata = metadata.reset_index()\n",
    "indices = pd.Series(metadata.index, index=metadata['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d1b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test  = train_test_split(df,test_size=0.2,stratify = df['Class Index'])\n",
    "X_train, X_val = train_test_split(X_train,test_size=0.20,stratify = X_train['Class Index'])\n",
    "\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df['body'], df['categories'], test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf = TfidfVectorizer(use_idf=False, sublinear_tf=True, min_df=5, norm='l2',\n",
    "                        encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "features = tfidf.fit_transform(df.body).toarray()\n",
    "labels = df.cat_id\n",
    "\n",
    "engines = [('PassiveAggressiveClassifier', PassiveAggressiveClassifier(fit_intercept=True, n_jobs=-1, random_state=0)),\n",
    "           ('NearestCentroid', NearestCentroid()), \n",
    "           ('RandomForestClassifier', RandomForestClassifier(min_samples_leaf=0.01))]\n",
    "\n",
    "\n",
    "\n",
    "for name, engine in engines:\n",
    "    clf = make_pipeline(tfidf, engine).fit(xtrain, ytrain)\n",
    "    prediction = clf.predict(xtest)\n",
    "    score = clf.score(xtest, prediction)\n",
    "    with lzma.open('./data/{}.pickle.xz'.format(name.lower()), 'wb') as f:\n",
    "        pickle.dump(clf, f, protocol=5)\n",
    "\n",
    "\n",
    "s = '''\n",
    "\n",
    "‘Guys, you’ve got to hear this,” I said. I was sitting in front of my computer one day in July 2012, with one eye on a screen of share prices and the other on a live stream of the House of Commons Treasury select committee hearings. As the Barclays share price took a graceful swan dive, I pulled my headphones out of the socket and turned up the volume so everyone could hear. My colleagues left their terminals and came around to watch BBC Parliament with me.\n",
    "\n",
    "It didn’t take long to realise what was happening. “Bob’s getting murdered,” someone said.\n",
    "\n",
    "Bob Diamond, the swashbuckling chief executive of Barclays, had been called before the committee to explain exactly what his bank had been playing at in regards to the Libor rate-fixing scandal. The day before his appearance, he had made things very much worse by seeming to accuse the deputy governor of the Bank of England of ordering him to fiddle an important benchmark, then walking back the accusation as soon as it was challenged. He was trying to turn on his legendary charm in front of a committee of angry MPs, and it wasn’t working. On our trading floor, in Mayfair, calls were coming in from all over the City. Investors needed to know what was happening and whether the damage was reparable.\n",
    "\n",
    "A couple of weeks later, the damage was done. The money was gone, Diamond was out of a job and the market, as it always does, had moved on. We were left asking ourselves: How did we get it so wrong?\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "result = []\n",
    "for file in glob.glob('./data/*.pickle.xz'):\n",
    "  clf   = pickle.load(lzma.open('{}'.format(file), 'rb'))\n",
    "  ypred = clf.predict([s])\n",
    "  score = clf.score([s], ypred)\n",
    "  print(file, ypred[0], score)\n",
    "  result.append(ypred[0])\n",
    "\n",
    "print(pd.io.json.dumps(Counter(result), indent=4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad3112d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe7f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5dc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here, I will use the below machine learning algorithms then I will select the best one based on its training time, accuracy score and f-beta scores.\n",
    "\n",
    "Support Vector Machine\n",
    "Ada Boost\n",
    "Gradient Boosting\n",
    "XG Boost\n",
    "Decision Tree\n",
    "Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d413509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate model\n",
    "def fit_eval_model(model, train_features, y_train, test_features, y_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function: train and evaluate a machine learning classifier.\n",
    "    Args:\n",
    "      model: machine learning classifier\n",
    "      train_features: train data extracted features\n",
    "      y_train: train data lables\n",
    "      test_features: train data extracted features\n",
    "      y_test: train data lables\n",
    "    Return:\n",
    "      results(dictionary): a dictionary of the model training time and classification report\n",
    "    \"\"\"\n",
    "    results ={}\n",
    "    \n",
    "    # Start time\n",
    "    start = time.time()\n",
    "    # Train the model\n",
    "    model.fit(train_features, y_train)\n",
    "    # End time\n",
    "    end = time.time()\n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "    \n",
    "    # Test the model\n",
    "    train_predicted = model.predict(train_features)\n",
    "    test_predicted = model.predict(test_features)\n",
    "    \n",
    "     # Classification report\n",
    "    results['classification_report'] = classification_report(y_test, test_predicted)\n",
    "        \n",
    "    return results\n",
    "    \n",
    "# Initialize the models\n",
    "sv = svm.SVC()\n",
    "ab = AdaBoostClassifier(random_state = 1)\n",
    "gb = GradientBoostingClassifier(random_state = 1)\n",
    "xgb = xgboost.XGBClassifier(random_state = 1)\n",
    "tree = DecisionTreeClassifier()\n",
    "nb = MultinomialNB()\n",
    "\n",
    "\n",
    "# Fit and evaluate models\n",
    "results = {}\n",
    "for cls in [sv, ab, gb, xgb, tree, nb]:\n",
    "    cls_name = cls.__class__.__name__\n",
    "    results[cls_name] = {}\n",
    "    results[cls_name] = fit_eval_model(cls, train_features, y_train, test_features, y_test)\n",
    "    \n",
    "# Print classifiers results\n",
    "for res in results:\n",
    "    print (res)\n",
    "    print()\n",
    "    for i in results[res]:\n",
    "        print (i, ':')\n",
    "        print(results[res][i])\n",
    "        print()\n",
    "    print ('-----')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d2909b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868e4ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
